{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11271932,"sourceType":"datasetVersion","datasetId":7046285},{"sourceId":11272219,"sourceType":"datasetVersion","datasetId":7046498}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Projet","metadata":{}},{"cell_type":"code","source":"# Evaluation du modele\n\n# Charger le mod√®le entra√Æn√©\nif path.exists(\"/kaggle/working/password_lstm_attention.pt\"):\n    decoder = torch.load(\"/kaggle/working/password_lstm_attention.pt\").to(device)\n    decoder.eval()  # Mettre le mod√®le en mode √©valuation\n    print(\"‚úÖ Mod√®le charg√© avec succ√®s !\")\nelse:\n    print(\"‚ùå Erreur : mod√®le introuvable.\")\n    exit()\n\n# Charger les donn√©es de validation\ntry:\n    val_file = unidecode(open(\"/kaggle/input/validation2/validation2.txt\").read())\n    val_file_len = len(val_file)\nexcept FileNotFoundError:\n    print(\"‚ùå Erreur : Le fichier validation2.txt est introuvable.\")\n    exit()\n\n# Fonction pour obtenir un batch de validation\ndef validation_set():\n    start_index = random.randint(0, val_file_len - chunk_len - 1)\n    end_index = start_index + chunk_len + 1\n    chunk = val_file[start_index:end_index]\n    inp = char_tensor(chunk[:-1])\n    target = char_tensor(chunk[1:])\n    return inp, target\n\n# ----------------------------------------------------------------------------------\n# 1) utilitaires pour convertir indices ‚áÑ caract√®res\n# ----------------------------------------------------------------------------------\nall_characters = (\n    \"abcdefghijklmnopqrstuvwxyz\"\n    \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n    \"0123456789\"\n    \"!@#$%^&*()-_=+[]{};:'\\\",.<>?/\\\\|`~ \"   # m√™mes caract√®res que pendant l'entra√Ænement\n)\nn_characters = len(all_characters)\n\ndef idx_to_char(idx):\n    return all_characters[idx]\n\ndef tensor_to_string(tensor):\n    \"\"\"Convertit un tensor d'indices en cha√Æne de caract√®res.\"\"\"\n    chars = [idx_to_char(i.item()) for i in tensor]\n    return \"\".join(chars)\n\n\n# Fonction d'√©valuation\ndef evaluate_model(num_samples=500, return_samples=False, save_to_file=None):\n    \"\"\"\n    - num_samples       : nombre de s√©quences tir√©es dans la validation\n    - return_samples    : si True, renvoie la liste (pred, target)\n    - save_to_file      : chemin d‚Äôun fichier .txt pour y √©crire les pr√©dictions\n    \"\"\"\n    total_loss = 0\n    correct = 0\n    total = 0\n    all_losses = []\n    samples = []  # stocke les couples (prediction, ground‚Äëtruth)\n\n    # ouvrir le fichier de sortie si demand√©\n    f_out = open(save_to_file, \"w\", encoding=\"utf‚Äë8\") if save_to_file else None\n\n    with torch.no_grad():\n        for _ in range(num_samples):\n            inp, target = validation_set()\n            hidden = decoder.init_hidden()\n            loss = 0\n            seq_len = inp.size(0)\n\n            predicted_chars = []  # caract√®res g√©n√©r√©s pour CETTE s√©quence\n\n            for c in range(seq_len):\n                output, hidden = decoder(inp[c].unsqueeze(0), hidden)\n                loss += criterion(output, target[c].unsqueeze(0))\n\n                # indice pr√©dit\n                pred_idx = output.argmax(dim=1).item()\n                predicted_chars.append(idx_to_char(pred_idx))\n\n                # accuracy char‚Äëpar‚Äëchar\n                correct += (pred_idx == target[c].item())\n                total += 1\n\n            loss = loss.item() / seq_len\n            total_loss += loss\n            all_losses.append(loss)\n\n            # reconstruction texte\n            pred_str   = \"\".join(predicted_chars)\n            target_str = tensor_to_string(target)\n\n            # m√©morise ou √©crit\n            if return_samples:\n                samples.append((pred_str, target_str))\n            if f_out:\n                #f_out.write(f\"{pred_str}\\t{target_str}\\n\")\n                f_out.write(f\"{target_str}\\n\")\n\n    if f_out:\n        f_out.close()\n\n    avg_loss = total_loss / num_samples\n    accuracy = correct / total * 100  # pr√©cision par caract√®re\n\n    if return_samples:\n        return avg_loss, accuracy, all_losses, samples\n    else:\n        return avg_loss, accuracy, all_losses\n\n# ----------------------------------------------------------------------------------\n# 3) appel de la fonction\n# ----------------------------------------------------------------------------------\nval_loss, val_accuracy, all_losses, preds = evaluate_model(\n    num_samples=20_000,          # ou moins si vous ne voulez pas saturer l‚Äôoutput\n    return_samples=True,         # renvoie la liste des (prediction, cible)\n    save_to_file=\"predictions.txt\"  # optionnel : √©crit tout dans ce fichier\n)\n\nprint(f\"\\nüìä R√©sultats sur {len(preds)} √©chantillons‚ÄØ:\")\nprint(f\"   - Validation Loss     : {val_loss:.4f}\")\nprint(f\"   - Validation Accuracy : {val_accuracy:.2f}%\\n\")\n\n# aper√ßu des 20‚ÄØpremi√®res pr√©dictions\nfor i, (p, t) in enumerate(preds[:20], 1):\n    print(f\"{i:02d}. pred: {p}   |   target: {t}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:14:08.441021Z","iopub.execute_input":"2025-05-05T15:14:08.441359Z","iopub.status.idle":"2025-05-05T15:16:31.447696Z","shell.execute_reply.started":"2025-05-05T15:14:08.441336Z","shell.execute_reply":"2025-05-05T15:16:31.446649Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-5-84b247bb891f>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  decoder = torch.load(\"/kaggle/working/password_lstm_attention.pt\").to(device)\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ Mod√®le charg√© avec succ√®s !\n\nüìä R√©sultats sur 20000 √©chantillons‚ÄØ:\n   - Validation Loss     : 3.3613\n   - Validation Accuracy : 17.35%\n\n01. pred: aaaaaaaaaaaa   |   target: aahsitesacja\n02. pred: aaaaaaaaaaaa   |   target: 1acspartan05\n03. pred: aaaaaaaaaaaa   |   target: ewee1af4fhel\n04. pred: aaaaaaaaaaaa   |   target: orko1999aulo\n05. pred: aaaaaaaaaaaa   |   target: afour1111ac8\n06. pred: aaaaaaaaaaaa   |   target: 4abobsvala69\n07. pred: aaaaaaaaaaaa   |   target: demerlliusag\n08. pred: aaaaaaaaaaaa   |   target: 123amarch292\n09. pred: aaaaaaaaaaaa   |   target: be1179abarbe\n10. pred: aaaaaaaaaaaa   |   target: hachinoheabo\n11. pred: aaaaaaaaaaaa   |   target: latortaabamb\n12. pred: aaaaaaaaaaaa   |   target: afindsexamed\n13. pred: aaaaaaaaaaaa   |   target: 72a194400ama\n14. pred: aaaaaaaaaaaa   |   target: pectre170age\n15. pred: aaaaaaaaaaaa   |   target: orola2a62206\n16. pred: aaaaaaaaaaaa   |   target: a83594abiff1\n17. pred: aaaaaaaaaaaa   |   target: trell1aboney\n18. pred: aaaaaaaaaaaa   |   target: awboy454apho\n19. pred: aaaaaaaaaaaa   |   target: n^#036{123ag\n20. pred: aaaaaaaaaaaa   |   target: reezi28abamb\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# dernir code\n# Installer unidecode si n√©cessaire\n!pip install unidecode\n\nimport string\nimport random\nimport torch\nimport torch.nn as nn\nimport time, math\nimport matplotlib.pyplot as plt\nfrom os import path, makedirs\nfrom unidecode import unidecode\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Ensembles des caract√®res pour les mots de passe\nall_characters = string.ascii_letters + string.digits + string.punctuation\nselected = string.ascii_letters + string.digits + string.punctuation\nnot_selected = string.whitespace\nn_characters = len(all_characters)\n\nchunk_len = 12\nhidden_size = 256\nn_layers = 2\nlr = 0.005\nn_epochs = 3000\n\n# Chargement des donn√©es\nfile = unidecode(open(\"/kaggle/input/train2/train2.txt\").read())\nfile_len = len(file)\n\ndef random_chunk():\n    start_index = random.randint(0, file_len - chunk_len - 1)\n    end_index = start_index + chunk_len + 1\n    return file[start_index:end_index]\n\ndef char_tensor(string):\n    tensor = torch.zeros(len(string)).long()\n    for c in range(len(string)):\n        if string[c] in not_selected:\n            continue\n        tensor[c] = selected.index(string[c])\n    return tensor.to(device)\n\ndef random_training_set():\n    chunk = random_chunk()\n    inp = char_tensor(chunk[:-1])\n    target = char_tensor(chunk[1:])\n    return inp, target\n\n# LSTM bidirectionnel avec Attention corrig√©\nclass BiLSTMWithAttention(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size, n_layers):\n        super(BiLSTMWithAttention, self).__init__()\n        self.embedding = nn.Embedding(input_size, hidden_size)\n        self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers, bidirectional=True, batch_first=True)\n\n        # Correction : attention adapt√©e √† un LSTM bidirectionnel\n        self.attn = nn.Linear(hidden_size * 2, hidden_size * 2)\n        self.fc = nn.Linear(hidden_size * 2, output_size)\n\n    def forward(self, x, hidden):\n        x = self.embedding(x).view(1, -1, hidden_size)\n        output, (hn, cn) = self.lstm(x, hidden)\n\n        # M√©canisme d'attention corrig√©\n        attn_weights = torch.softmax(self.attn(output.squeeze(0)), dim=1)\n        attn_output = output.squeeze(0) * attn_weights  # Application de l'attention\n        output = self.fc(attn_output)\n\n        return output, (hn, cn)\n\n    def init_hidden(self):\n        return (torch.zeros(n_layers * 2, 1, hidden_size, device=device),\n                torch.zeros(n_layers * 2, 1, hidden_size, device=device))\n\n# Initialisation du mod√®le\ndecoder = BiLSTMWithAttention(n_characters, hidden_size, n_characters, n_layers).to(device)\noptimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\ncriterion = nn.CrossEntropyLoss()\n\nall_losses = []  # Stockage des pertes\n\n# Fonction d'entra√Ænement\ndef train(inp, target):\n    hidden = decoder.init_hidden()\n    decoder.zero_grad()\n    loss = 0\n    seq_len = inp.size(0)\n\n    for c in range(seq_len):\n        output, hidden = decoder(inp[c].unsqueeze(0), hidden)\n        loss += criterion(output, target[c].unsqueeze(0))\n\n    loss.backward()\n    optimizer.step()\n\n    all_losses.append(loss.item() / seq_len)\n    return loss.item() / seq_len\n\n# Fonction de g√©n√©ration de mots de passe\ndef evaluate(prime_str='A', predict_len=None, temperature=0.8):\n    if predict_len is None:\n        predict_len = random.randint(5, 12)\n\n    hidden = decoder.init_hidden()\n    prime_input = char_tensor(prime_str)\n    predicted = prime_str\n\n    for p in range(len(prime_str) - 1):\n        _, hidden = decoder(prime_input[p].unsqueeze(0), hidden)\n    inp = prime_input[-1]\n\n    for _ in range(predict_len):\n        output, hidden = decoder(inp.unsqueeze(0), hidden)\n        output_dist = torch.softmax(output.view(-1) / temperature, dim=0)\n        top_i = torch.multinomial(output_dist[:len(selected)], 1)[0]\n        predicted_char = selected[top_i]\n        predicted += predicted_char\n        inp = torch.tensor([top_i], dtype=torch.long).to(device)\n\n    return predicted\n\n# Fonction pour mesurer le temps √©coul√©\ndef time_since(since):\n    s = time.time() - since\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n# Lissage exponentiel des pertes\ndef exponential_moving_average(values, alpha=0.01):\n    ema = []\n    avg = values[0]\n    for value in values:\n        avg = alpha * value + (1 - alpha) * avg\n        ema.append(avg)\n    return ema\n\n# Lancement de l'entra√Ænement\nprint(\"Entra√Ænement sur le dataset de mots de passe...\")\nstart = time.time()\n\nfor epoch in range(1, n_epochs + 1):\n    loss = train(*random_training_set())\n    if epoch % 1000 == 0:\n        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n\n# Affichage de la courbe de perte\nsmoothed_losses = exponential_moving_average(all_losses, alpha=0.01)\nplt.plot(smoothed_losses, label='Loss liss√©e (EMA)')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Courbe de la perte pendant l\\'entra√Ænement (liss√©e)')\nplt.legend()\nplt.show()\n\n# Sauvegarde du mod√®le\nif not path.exists(\"models\"):\n    makedirs(\"models\")\ntorch.save(decoder, \"/kaggle/working/password_lstm_attention.pt\")\n\n# G√©n√©ration de mots de passe apr√®s entra√Ænement\nprint(\"\\nG√©n√©ration de mots de passe apr√®s entra√Ænement :\\n\")\nfor _ in range(10):\n    random_length = random.randint(5, 12)\n    print(evaluate(prime_str=random.choice(selected), predict_len=random_length, temperature=0.7))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:02:08.018687Z","iopub.execute_input":"2025-05-05T15:02:08.019123Z","iopub.status.idle":"2025-05-05T15:02:11.342869Z","shell.execute_reply.started":"2025-05-05T15:02:08.019087Z","shell.execute_reply":"2025-05-05T15:02:11.341563Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: unidecode in /usr/local/lib/python3.10/dist-packages (1.4.0)\n^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0mEntra√Ænement sur le dataset de mots de passe...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-265daa0864e4>\u001b[0m in \u001b[0;36m<cell line: 143>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrandom_training_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[%s (%d %d%%) %.4f]'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime_since\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-265daa0864e4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(inp, target)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":3},{"cell_type":"code","source":"# Evaluation du modele\n\n# Charger le mod√®le entra√Æn√©\nif path.exists(\"/kaggle/working/password_lstm_attention.pt\"):\n    decoder = torch.load(\"/kaggle/working/password_lstm_attention.pt\").to(device)\n    decoder.eval()  # Mettre le mod√®le en mode √©valuation\n    print(\"‚úÖ Mod√®le charg√© avec succ√®s !\")\nelse:\n    print(\"‚ùå Erreur : mod√®le introuvable.\")\n    exit()\n\n# Charger les donn√©es de validation\ntry:\n    val_file = unidecode(open(\"/kaggle/input/validation2/validation2.txt\").read())\n    val_file_len = len(val_file)\nexcept FileNotFoundError:\n    print(\"‚ùå Erreur : Le fichier validation2.txt est introuvable.\")\n    exit()\n\n# Fonction pour obtenir un batch de validation\ndef validation_set():\n    start_index = random.randint(0, val_file_len - chunk_len - 1)\n    end_index = start_index + chunk_len + 1\n    chunk = val_file[start_index:end_index]\n    inp = char_tensor(chunk[:-1])\n    target = char_tensor(chunk[1:])\n    return inp, target\n\n# Fonction d'√©valuation\ndef evaluate_model(num_samples=500):\n    total_loss = 0\n    correct = 0\n    total = 0\n    all_losses = []\n\n    \n\n    with torch.no_grad():  # D√©sactiver le calcul des gradients\n        for _ in range(num_samples):  # Tester sur plusieurs √©chantillons\n            inp, target = validation_set()\n            hidden = decoder.init_hidden()\n            loss = 0\n            seq_len = inp.size(0)\n\n            for c in range(seq_len):\n                output, hidden = decoder(inp[c].unsqueeze(0), hidden)\n                loss += criterion(output, target[c].unsqueeze(0))\n\n                # Calcul de l'accuracy\n                pred = output.argmax(dim=1)  # Trouver l'indice de la meilleure pr√©diction\n                correct += (pred == target[c]).sum().item()\n                total += 1\n\n            loss = loss.item() / seq_len\n            total_loss += loss\n            all_losses.append(loss)\n\n    avg_loss = total_loss / num_samples  # Moyenne des pertes\n    accuracy = correct / val_file_len * 100  # Pr√©cision en %\n\n    return avg_loss, accuracy, all_losses\n\n# Ex√©cuter l'√©valuation\nval_loss, val_accuracy, all_losses = evaluate_model(num_samples=20000)\n\nprint(f\"\\nüìä R√©sultats de la validation sur 100000 √©chantillons :\")\nprint(f\"   - Validation Loss : {val_loss:.4f}\")\nprint(f\"   - Validation Accuracy : {val_accuracy:.2f}%\")\n\n# Affichage des r√©sultats sous forme graphique\nplt.figure(figsize=(12, 5))\n\n# Graphique de la distribution des pertes\nplt.hist(all_losses, bins=30, color=\"blue\", alpha=0.7)\nplt.xlabel(\"Loss par s√©quence\")\nplt.ylabel(\"Nombre d'occurrences\")\nplt.title(\"Distribution des pertes sur l'ensemble de validation\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T14:36:40.725862Z","iopub.execute_input":"2025-05-05T14:36:40.726166Z","iopub.status.idle":"2025-05-05T14:39:09.885495Z","shell.execute_reply.started":"2025-05-05T14:36:40.726145Z","shell.execute_reply":"2025-05-05T14:39:09.884622Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Mod√®le charg√© avec succ√®s !\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-2-cc4bccdf03cd>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  decoder = torch.load(\"/kaggle/working/password_lstm_attention.pt\").to(device)\n","output_type":"stream"},{"name":"stdout","text":"\nüìä R√©sultats de la validation sur 100000 √©chantillons :\n   - Validation Loss : 3.3572\n   - Validation Accuracy : 6.40%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x500 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import os\nimport torch\nimport random\nimport matplotlib.pyplot as plt\nfrom unidecode import unidecode\nfrom os import path\nimport string\n\n# Activer le mode de d√©bogage CUDA\nos.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n\n# === PARAM√àTRES √Ä AJUSTER SELON TON CODE === #\nchunk_len = 12  # longueur du mot de passe g√©n√©r√©\nall_characters = string.ascii_letters + string.digits + string.punctuation + \" \"\nn_characters = len(all_characters)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Fonction am√©lior√©e pour convertir un texte en tensor avec v√©rification explicite\ndef char_tensor(string):\n    tensor = torch.zeros(len(string)).long()\n    for c in range(len(string)):\n        if string[c] in all_characters:\n            tensor[c] = all_characters.index(string[c])\n        else:\n            raise ValueError(f\"Caract√®re inconnu d√©tect√© : '{string[c]}' √† la position {c}\")\n    return tensor.to(device)\n\n# Charger le mod√®le entra√Æn√©\nif path.exists(\"/kaggle/working/password_lstm_attention.pt\"):\n    decoder = torch.load(\"/kaggle/working/password_lstm_attention.pt\", map_location=device)\n    decoder.eval()\n    print(\"‚úÖ Mod√®le charg√© avec succ√®s !\")\nelse:\n    print(\"‚ùå Erreur : mod√®le introuvable.\")\n    exit()\n\n# Charger les donn√©es de validation\ntry:\n    val_file = unidecode(open(\"/kaggle/input/validation2/validation2.txt\").read())\n    val_file_len = len(val_file)\nexcept FileNotFoundError:\n    print(\"‚ùå Erreur : Le fichier validation2.txt est introuvable.\")\n    exit()\n\n# Identifier les caract√®res manquants\nchars_dataset = set(val_file)\nchars_manquants = chars_dataset - set(all_characters)\n\nif chars_manquants:\n    print(\"‚ö†Ô∏è Caract√®res manquants d√©tect√©s dans ton jeu de donn√©es :\")\n    print(chars_manquants)\n\n    # Ajouter automatiquement les caract√®res manquants\n    all_characters += ''.join(sorted(chars_manquants))\n    n_characters = len(all_characters)\n    print(\"‚úÖ Alphabet mis √† jour :\", all_characters)\nelse:\n    print(\"‚úÖ Aucun caract√®re manquant.\")\n\n# Fonction pour obtenir un batch de validation\ndef validation_set():\n    start_index = random.randint(0, val_file_len - chunk_len - 1)\n    end_index = start_index + chunk_len + 1\n    chunk = val_file[start_index:end_index]\n    inp = char_tensor(chunk[:-1])\n    target = char_tensor(chunk[1:])\n    return inp, target\n\n# Fonction d'√©valuation compl√®te avec v√©rifications int√©gr√©es\ndef evaluate_model(num_samples=500):\n    total_loss = 0\n    correct = 0\n    total = 0\n    all_losses = []\n    criterion = torch.nn.CrossEntropyLoss()\n\n    with torch.no_grad():\n        for sample_idx in range(1, num_samples + 1):\n            inp, target = validation_set()\n            hidden = decoder.init_hidden()\n            loss = 0\n            seq_len = inp.size(0)\n            generated_password = \"\"\n\n            for c in range(seq_len):\n                output, hidden = decoder(inp[c].unsqueeze(0), hidden)\n                loss += criterion(output, target[c].unsqueeze(0))\n\n                pred_idx = output.argmax(dim=1).item()\n                generated_password += all_characters[pred_idx]\n\n                correct += (pred_idx == target[c].item())\n                total += 1\n\n            loss = loss.item() / seq_len\n            total_loss += loss\n            all_losses.append(loss)\n\n            # Afficher le mot de passe g√©n√©r√© pour cet √©chantillon\n            print(f\"üîë √âchantillon {sample_idx}/{num_samples} : {generated_password} (loss : {loss:.4f})\")\n\n    avg_loss = total_loss / num_samples\n    accuracy = correct / total * 100\n\n    return avg_loss, accuracy, all_losses\n\n# Ex√©cuter l'√©valuation\nval_loss, val_accuracy, all_losses = evaluate_model(num_samples=2000)\n\n# Affichage r√©sum√©\nprint(f\"\\nüìä R√©sultats globaux sur l'ensemble de validation :\")\nprint(f\"   - Validation Loss : {val_loss:.4f}\")\nprint(f\"   - Validation Accuracy : {val_accuracy:.2f}%\")\n\n# Graphique de distribution des pertes\nplt.figure(figsize=(12, 5))\nplt.hist(all_losses, bins=30, color=\"blue\", alpha=0.7)\nplt.xlabel(\"Loss par s√©quence\")\nplt.ylabel(\"Nombre d'occurrences\")\nplt.title(\"Distribution des pertes sur l'ensemble de validation\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install unidecode\n\nimport unidecode\nimport string\nimport random\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport time, math\nimport matplotlib.pyplot as plt\nfrom os import path, makedirs\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nall_characters = string.ascii_letters + string.digits + string.punctuation\nend_char = '&'\nselected = string.ascii_letters + string.digits + end_char\nn_characters = len(all_characters)\nn_characters_selected = len(selected)\n\nchunk_len = 12\n\nhidden_size = 256\nn_layers = 2\nlr = 0.005\nn_epochs = 3000\n\n\ntrain_file = unidecode.unidecode(open(\"sample_data/train2_with_&.txt\").read())\ntrain_file_len = len(train_file)\nval_file = unidecode.unidecode(open(\"sample_data/validation2.txt\").read())\nval_file_len = len(val_file)\n\ndef random_chunk(file, file_len):\n  start_index = random.randint(0, file_len - chunk_len - 1)\n  end_index = start_index + chunk_len + 1\n  return file[start_index:end_index]\n\ndef char_tensor(string):\n  tensor = torch.zeros(len(string)).long()\n  for c in range(len(string)):\n    if string[c] not in selected:\n      continue\n    tensor[c] = selected.index(string[c])\n  return tensor.to(device)\n\ndef random_training_set(file, file_len):\n  chunk = random_chunk(file, file_len)\n  inp = char_tensor(chunk[:-1])\n  target = char_tensor(chunk[1:])\n  return inp, target\n\nclass RNN(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n        super(RNN, self).__init__()\n        self.encoder = nn.Embedding(input_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n        self.decoder = nn.Linear(hidden_size, output_size)\n        self.hidden_size = hidden_size\n        self.n_layers = n_layers\n\n    def forward(self, input, hidden):\n        input = self.encoder(input.view(1, -1))\n        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n        output = self.decoder(output.view(1, -1))\n        return output, hidden\n\n    def init_hidden(self):\n        return torch.zeros(self.n_layers, 1, self.hidden_size, device=device)\n\n\ndef train(inp, target):\n  hidden = decoder.init_hidden()\n  decoder.zero_grad()\n  loss = 0\n  seq_len = inp.size(0) # R√©cup√©rer la longueur du batch actuel\n  for c in range(seq_len):\n    output, hidden = decoder(inp[c], hidden)\n    loss += criterion(output, target[c].unsqueeze(0))\n  loss.backward()\n  optimizer.step()\n  train_losses.append(loss.item() / seq_len)\n  return loss.item() / seq_len\n\n\ndef evaluate(prime_str='A', predict_len=25, temperature=0.8):\n  if predict_len is None:\n    predict_len = random.randint(5, 12)\n\n  hidden = decoder.init_hidden()\n  prime_input = char_tensor(prime_str)\n  predicted = prime_str\n\n  for p in range(len(prime_str) - 1):\n    _, hidden = decoder(prime_input[p], hidden)\n  inp = prime_input[-1]\n\n  for _ in range(predict_len):\n    output, hidden = decoder(inp, hidden)\n    output_dist = torch.softmax(output.data.view(-1) / temperature, dim=0)\n    top_i = torch.multinomial(output_dist[:len(selected)], 1)[0]\n    predicted_char = selected[top_i]\n\n    if predicted_char == '&':\n      break\n\n    predicted += predicted_char\n    inp = torch.tensor([selected.index(predicted_char)]).to(device)\n\n  return predicted\n\n\ndef time_since(since):\n  s = time.time() - since\n  m = math.floor(s / 60)\n  s -= m * 60\n  return '%dm %ds' % (m, s)\n\ndef exponential_moving_average(values, alpha=0.01):\n  ema = []\n  avg = values[0] # Initialisation\n  for value in values:\n    avg = alpha * value + (1 - alpha) * avg\n    ema.append(avg)\n  return ema\n\ndef evaluate_loss(n_samples=1000):\n  total_loss = 0\n  for _ in range(n_samples):\n    inp, target = random_training_set(val_file, val_file_len)\n    hidden = decoder.init_hidden()\n    loss = 0\n  for c in range(inp.size(0)):\n    output, hidden = decoder(inp[c], hidden)\n  loss += criterion(output, target[c].unsqueeze(0))\n  total_loss += loss.item() / inp.size(0)\n  return total_loss / n_samples\n\ndecoder = RNN(n_characters, hidden_size, n_characters, n_layers).to(device)\noptimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\ncriterion = nn.CrossEntropyLoss()\n\ntrain_losses = []\neval_losses = []\nprint(\"Entra√Ænement sur le dataset de mots de passe...\")\n\nstart = time.time()\nfor epoch in range(1, n_epochs + 1):\n  loss = train(*random_training_set(train_file, train_file_len))\n  with torch.no_grad():\n    eval_loss = evaluate_loss(n_samples=50)\n    eval_losses.append(eval_loss)\n  if epoch % 1000 == 0:\n    print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n\nsmoothed_train_losses = exponential_moving_average(train_losses, alpha=0.01)\nsmoothed_eval_losses = exponential_moving_average(eval_losses, alpha=0.01)\n\nplt.plot(smoothed_train_losses, label='Loss liss√©e (EMA)')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Courbe de la perte pendant l\\'entra√Ænement (liss√©e)')\nplt.legend()\nplt.show()\n\nplt.plot(smoothed_eval_losses, label='Loss de validation')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Courbe de la perte de validation')\nplt.legend()\nplt.show()\n\n# save\n\nif not path.exists(\"models\"):\n  makedirs(\"models\")\ntorch.save(decoder, f\"models/password_rnn_{int(time.time())}.pt\")\n\nprint(\"nG√©n√©ration de mots de passe apr√®s entra√Ænement :n\")\nfor _ in range(10):\n  print(evaluate(prime_str=random.choice(selected), temperature=0.7))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
